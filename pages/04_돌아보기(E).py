import streamlit as st
import io
import os

from PIL import Image
from datetime import datetime
from streamlit_drawable_canvas import st_canvas

from langchain_core.messages.chat import ChatMessage
from langchain_openai import ChatOpenAI

from modules.multimodal import MultiModalwithHistory

st.session_state.api_key = st.secrets["openai_api_key"]

os.environ["LANGCHAIN_TRACING_V2"] = st.secrets["LANGCHAIN_TRACING_V2"]
os.environ["LANGCHAIN_API_KEY"] = st.secrets["LANGCHAIN_API_KEY"]
os.environ["LANGCHAIN_ENDPOINT"] = st.secrets["LANGCHAIN_ENDPOINT"]
os.environ["LANGCHAIN_PROJECT"] = st.secrets["LANGCHAIN_PROJECT"]

st.session_state["init_user_input"] = False

if "submit_button_disabled" not in st.session_state:
    st.session_state["submit_button_disabled"] = True

# ì²˜ìŒ 1ë²ˆë§Œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì½”ë“œ
if "messages_explanation" not in st.session_state:
    # ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•˜ê¸° ìœ„í•œ ìš©ë„ë¡œ ìƒì„±í•œë‹¤.
    st.session_state["messages_explanation"] = []

if "show_answer" not in st.session_state:
    st.session_state["show_answer"] = False

if "multimodal_chain" not in st.session_state:
    st.session_state["multimodal_chain"] = None

# def save_draw_image(numpy_array):
#     image = Image.fromarray(numpy_array)
#     current_time = datetime.now().strftime("%Y-%m-%d-%H-%M-%S")
#     file_name = f"e-drawing-{current_time}"
#     image.save(f"draw_images/{file_name}.png", format="PNG")
#     # return st.info("ì´ë¯¸ì§€ ì €ì¥ë¨")

def enalble_submit_button():
    st.session_state["submit_button_disabled"] = False

def disalble_submit_button():
    st.session_state["submit_button_disabled"] = True


st.title("ë¬¸ì œ ëŒì•„ë³´ê¸° âœ…")
st.info("- ì™¼ìª½ ìº”ë²„ìŠ¤ì— ìµœì¢…ì ìœ¼ë¡œ ìƒê°í•œ **(1)ì •ë‹µ**ê³¼ í•¨ê»˜ ê·¸ë ‡ê²Œ ìƒê°í•œ **(2)ì´ìœ **ë¥¼ ì ì–´ì£¼ì„¸ìš”. \n - ì •ë‹µì„ ì ìœ¼ë©´ í•˜ë‹¨ ì˜¤ë¥¸ìª½ 'ë¬¸ì œ ì •ë‹µ' íƒ­ì— ì±„ì  ê²°ê³¼ì™€ í”¼ë“œë°±ì´ ë‚˜ì˜µë‹ˆë‹¤. \n - AI íŠœí„°ì™€ ëŒ€í™”í•˜ë©´ì„œ ë‚´ê°€ ì˜ëª» ì•Œê³  ìˆë˜ ê°œë…ì€ ì—†ëŠ”ì§€ íŒŒì•…í•˜ê³  ë‚´ ì´í•´ë„ë¥¼ ë” ì •êµí™”í•´ë³´ì„¸ìš”.")

tab1, tab2 = st.tabs(["ë¬¸ì œ ìƒí™©", "ë¬¸ì œ ì •ë‹µ"])

with tab1:
    st.subheader("ë¬¸ì œ ìƒí™©")
    st.image("images/problem_1.png")

with tab2:
    togle = st.empty()
    if "explanation_user_drawing" in st.session_state and "explanation_user_reason" in st.session_state:
        togle.empty()
        st.subheader("ë¬¸ì œ ì •ë‹µ")
        st.image("images/review_1.png")
        # st.write(st.session_state)
        st.session_state["show_answer"] = True
    else:
        togle.error("ë‹µë³€ì„ ë¨¼ì € ì œì¶œí•´ì£¼ì„¸ìš”!")
        pass

# ì‚¬ì´ë“œë°” ìƒì„±
with st.sidebar:

    st.text("ìµœì¢…ì ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•´ë³´ì„¸ìš”.")
    st.text("(ì•„ë˜ ìº”ë²„ìŠ¤ì— ìƒê°í•œ ë‚´ìš©ì„ ê·¸ë ¤ë³´ì„¸ìš”ğŸ¨)")
    # Create a canvas component
    canvas_result = st_canvas(
        fill_color="rgba(255, 165, 0, 0.3)",  # Fixed fill color with some opacity
        stroke_width=3,
        stroke_color="#000000",
        background_color="#EEEEEE",
        background_image=None,
        update_streamlit=True,
        height=400,
        width=400,
        drawing_mode="freedraw",
        point_display_radius=0,
        key="canvas",
    )

    reason = st.text_area(
        label="ì™œ ê·¸ë ‡ê²Œ ìƒê°í–ˆëŠ”ì§€ ìì„¸íˆ ì ì–´ë³´ì„¸ìš”.",
        height=200,
        on_change=enalble_submit_button
    )

    if not reason:
        disalble_submit_button()

    submit_button = st.button(
        label="ì œì¶œí•˜ê¸°",
        type="primary",
        use_container_width=True,
        disabled=st.session_state["submit_button_disabled"]
    )

    if submit_button:
        st.session_state["explanation_user_drawing"] = canvas_result.image_data
        st.session_state["explanation_user_reason"] = reason
        st.success("ì œì¶œ ì™„ë£Œ!")

with tab2:
    if "explanation_user_drawing" in st.session_state and "explanation_user_reason" in st.session_state:
        if not st.session_state["show_answer"]:
            togle.empty()
            st.subheader("ë¬¸ì œ ì •ë‹µ")
            st.image("images/review_1.png")
            # st.write(st.session_state)
            st.session_state["show_answer"] = True
        else:
            pass


# ëª¨ë¸ ì„ íƒ ë©”ë‰´
selected_model = "gpt-4o-mini" # st.selectbox("LLM ì„ íƒ", ["gpt-4o", "gpt-4o-mini"], index=0)

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
system_prompt = """ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ëŒ€í™”í˜• í•™ìŠµì„ ë•ëŠ” **ë¬¼ë¦¬ íŠœí„°**ì…ë‹ˆë‹¤.  
**ëª©í‘œ:** í•™ìƒì´ 'ë“±ì† ì›ìš´ë™'ì—ì„œ í˜ì˜ ë°©í–¥ì´ ë¬¼ì²´ì˜ ìš´ë™ ê¶¤ì ì— ì–´ë–»ê²Œ ì‘ìš©í•˜ëŠ”ì§€ë¥¼ ì´í•´í•˜ë„ë¡ ë•ëŠ” ê²ƒì…ë‹ˆë‹¤. ì •ë‹µ í™”ë©´ì„ ì œê³µí•œ í›„, í•™ìƒì´ ì •ë‹µì„ ë…¼ë¦¬ì ìœ¼ë¡œ ì´í•´í•˜ê³  ì„¤ëª…í•  ìˆ˜ ìˆë„ë¡ ëŒ€í™”í˜• ì§ˆë¬¸ê³¼ ì„¤ëª…ì„ ì§„í–‰í•˜ì„¸ìš”.  
**ì¤‘ìš”:**  
1. ì •ë‹µì„ ë‹¨ìˆœíˆ ì œì‹œí•˜ëŠ” ë° ê·¸ì¹˜ì§€ ë§ê³ , í•™ìƒì´ ê·¸ ì´ìœ ë¥¼ ì´í•´í•˜ê³  ìì‹ ì˜ ì–¸ì–´ë¡œ ì •ë¦¬í•  ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.  
2. í•™ìƒì˜ ê´€ì ê³¼ ì§ˆë¬¸ì„ ì¡´ì¤‘í•˜ë©°, ì¹œê·¼í•œ ì¡´ëŒ“ë§ë¡œ ëŒ€í™”í•˜ì„¸ìš”.  
3. ê° ì‘ë‹µì€ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”(2ë¬¸ë‹¨ ì´ë‚´).  
4. í•™ìƒì´ ì´í•´í•˜ì§€ ëª»í•œ ë¶€ë¶„ì´ ìˆì„ ê²½ìš°, ì¶”ê°€ì ì¸ ì„¤ëª…ê³¼ ì˜ˆì‹œë¥¼ í™œìš©í•´ ê°œë…ì„ ëª…í™•íˆ ì „ë‹¬í•˜ì„¸ìš”.

**í”„ë¡¬í”„íŠ¸ ì‹œì‘ ì œì•ˆ:**  
(ì •ë‹µ í™”ë©´ì„ í•™ìƒì—ê²Œ ë³´ì—¬ì¤€ í›„ ëŒ€í™”ë¥¼ ì‹œì‘í•œë‹¤ê³  ìƒê°í•˜ì„¸ìš”.)
1. **ì •ë‹µ í™”ë©´ ì œì‹œ í›„**  
- "ì´ í™”ë©´ì—ì„œ ë¬¼ì²´ê°€ ë“±ì† ì›ìš´ë™ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ í˜ì´ ì–´ë–¤ ë°©í–¥ìœ¼ë¡œ ì‘ìš©í•˜ê³  ìˆëŠ”ì§€ ë³´ì—¬ì£¼ê³  ìˆì–´ìš”. ì—¬ê¸°ì„œ í˜ì˜ ë°©í–¥ì´ ì›ì˜ ì¤‘ì‹¬ì„ í–¥í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."  
2. **ì²« ì§ˆë¬¸:**  
- "ì´ í™”ë©´ì—ì„œ í˜ì´ ì™œ ì›ì˜ ì¤‘ì‹¬ì„ í–¥í•´ì•¼ í•˜ëŠ”ì§€ ìƒê°í•´ ë³´ì…¨ë‚˜ìš”? ì§€ê¸ˆê¹Œì§€ì˜ ê´€ì°°ê³¼ ê·¸ë¦¼ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ë²ˆ ì„¤ëª…í•´ ë³´ì„¸ìš”."  

**ëŒ€í™” ì „ëµ:**  
1. í•™ìƒì˜ ë‹µë³€ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì„ ì´ì–´ê°€ë©° ì˜¬ë°”ë¥¸ ê°œë…ì„ ë„ì¶œí•˜ë„ë¡ ë•ìŠµë‹ˆë‹¤.  
2. ëŒ€í™”ì˜ ì´ˆì ì€ í•™ìƒì´ 'ë“±ì† ì›ìš´ë™ì—ì„œ ì†ë„ì˜ ë°©í–¥ì´ ê³„ì† ë°”ë€Œê¸° ë•Œë¬¸ì— ì¤‘ì‹¬ ë°©í–¥ì˜ í˜(êµ¬ì‹¬ë ¥)ì´ í•„ìš”í•˜ë‹¤'ëŠ” ì ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ì´í•´í•˜ëŠ” ë° ë§ì¶°ì•¼ í•©ë‹ˆë‹¤.  
3. ì •ë‹µ í™”ë©´ì„ ì°¸ê³ í•˜ë©° í•™ìƒì˜ ì¶”ë¡  ê³¼ì •ì„ êµ¬ì²´í™”í•˜ë„ë¡ ì§ˆë¬¸ì„ í™œìš©í•˜ì„¸ìš”.

**í•µì‹¬ ì§ˆë¬¸ ìœ ë„:**  
- "ë“±ì† ì›ìš´ë™ì—ì„œëŠ” ë¬¼ì²´ì˜ ì†ë ¥ì´ ì¼ì •í•˜ì§€ë§Œ, ì†ë„ì˜ ë°©í–¥ì€ ê³„ì† ë³€í•©ë‹ˆë‹¤. ì†ë„ì˜ ë°©í–¥ì„ ë°”ê¾¸ê¸° ìœ„í•´ í˜ì´ ì–´ë–¤ ì—­í• ì„ í•œë‹¤ê³  ìƒê°í•˜ë‚˜ìš”?"  
- "ì´ ì •ë‹µ í™”ë©´ì—ì„œ ë³´ì´ëŠ” í˜ì˜ ë°©í–¥ì´ ì†ë„ì™€ ì§ê°ì„ ì´ë£¨ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¼ê¹Œìš”?"  
- "ë§Œì•½ í˜ì´ ì¤‘ì‹¬ì„ í–¥í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´, ë¬¼ì²´ì˜ ìš´ë™ ê¶¤ì ì€ ì–´ë–»ê²Œ ë ê¹Œìš”?"  

**ì¶”ê°€ì ì¸ ì„¤ëª… ì œê³µ:**  
í•™ìƒì´ ë‹µì„ ì´í•´í•˜ì§€ ëª»í•˜ê±°ë‚˜ ì˜ëª»ëœ ì¶”ë¡ ì„ ì œì‹œí–ˆì„ ê²½ìš°, ì˜¬ë°”ë¥¸ ê°œë…ì„ ì„¤ëª…í•˜ì„¸ìš”.  
- "ë“±ì† ì›ìš´ë™ì€ ë¬¼ì²´ê°€ ì¼ì •í•œ ì†ë ¥ìœ¼ë¡œ ì› ê¶¤ë„ë¥¼ ë”°ë¼ ì›€ì§ì´ëŠ” ìš´ë™ì´ì—ìš”. í•˜ì§€ë§Œ ì†ë„ì˜ ë°©í–¥ì´ ê³„ì† ë°”ë€Œê¸° ë•Œë¬¸ì— ê°€ì†ë„ê°€ ì¡´ì¬í•˜ê²Œ ë©ë‹ˆë‹¤. ì´ ê°€ì†ë„ë¥¼ ë§Œë“¤ì–´ë‚´ê¸° ìœ„í•´ì„œëŠ” í•­ìƒ ì›ì˜ ì¤‘ì‹¬ ë°©í–¥ìœ¼ë¡œ í˜ì´ ì‘ìš©í•´ì•¼ í•´ìš”. ì´ë¥¼ êµ¬ì‹¬ë ¥ì´ë¼ê³  í•©ë‹ˆë‹¤."  
- "ë§Œì•½ í˜ì´ ì¤‘ì‹¬ ë°©í–¥ìœ¼ë¡œ ì‘ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´, ë¬¼ì²´ëŠ” ì§ì„ ìœ¼ë¡œ ìš´ë™ì„ ê³„ì†í•˜ë ¤ëŠ” ê²½í–¥(ê´€ì„±)ì— ì˜í•´ ì› ê¶¤ë„ë¥¼ ë²—ì–´ë‚˜ê²Œ ë©ë‹ˆë‹¤."  

**ëŒ€í™” ë§ˆë¬´ë¦¬:**  
í•™ìƒì´ ìì‹ ì˜ ì–¸ì–´ë¡œ ê°œë…ì„ ì •ë¦¬í•  ìˆ˜ ìˆë„ë¡ ìœ ë„í•˜ì„¸ìš”.  
- "ì§€ê¸ˆê¹Œì§€ ë°°ìš´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •ë¦¬í•´ ë³¼ê¹Œìš”? ë¬¼ì²´ê°€ ë“±ì† ì›ìš´ë™ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ í˜ì˜ ë°©í–¥ì´ ì™œ ì›ì˜ ì¤‘ì‹¬ì„ í–¥í•´ì•¼ í•˜ëŠ”ì§€ ì„¤ëª…í•´ ì£¼ì„¸ìš”."  
- "ì •ë‹µ í™”ë©´ì„ ë‹¤ì‹œ ë³´ë©´ì„œ í˜ì˜ ë°©í–¥ê³¼ ìš´ë™ ê¶¤ì ì˜ ê´€ê³„ë¥¼ í•œ ë²ˆ ë” ì •ë¦¬í•´ ë³´ì„¸ìš”. ì™œ ë“±ì† ì›ìš´ë™ì—ì„œ ì¤‘ì‹¬ ë°©í–¥ì˜ í˜ì´ í•„ìš”í•œì§€, ê·¸ê²ƒì´ ì–´ë–»ê²Œ ìš´ë™ì„ ìœ ì§€í•˜ëŠ”ì§€ ì„¤ëª…í•  ìˆ˜ ìˆë‚˜ìš”?"  

**ì¤‘ìš” ì‚¬í•­:**  
- í•™ìƒì´ ìŠ¤ìŠ¤ë¡œ ì„¤ëª…í•˜ë ¤ê³  í•  ë•Œ ê²©ë ¤í•˜ë©°, ì˜ëª»ëœ í‘œí˜„ì´ ìˆì–´ë„ ë°”ë¡œ ì •ì •í•˜ì§€ ë§ê³  ì¶”ê°€ ì§ˆë¬¸ìœ¼ë¡œ ì‚¬ê³ ë¥¼ í™•ì¥í•˜ë„ë¡ ìœ ë„í•˜ì„¸ìš”.  
- ì •ë‹µ í™”ë©´ê³¼ í•™ìƒì˜ ì¶”ë¡  ê³¼ì •ì„ ì—°ê²°ì‹œí‚¤ëŠ” ë° ì§‘ì¤‘í•˜ë©°, ì´í•´ê°€ ì™„ë²½í•´ì§ˆ ë•Œê¹Œì§€ ì¸ë‚´ì‹¬ì„ ê°€ì§€ê³  ë•ìŠµë‹ˆë‹¤."""


# ì´ì „ ëŒ€í™”ë¥¼ ì¶œë ¥
def print_messages():
    for chat_message in st.session_state["messages_explanation"]:
        st.chat_message(chat_message.role).write(chat_message.content)


# ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¶”ê°€
def add_message(role, message):
    st.session_state["messages_explanation"].append(ChatMessage(role=role, content=message))


# Function to convert PNG to BytesIO
def png_to_bytesio(ndarray_file):
    # Open the PNG image
    with Image.fromarray(ndarray_file) as img:
        # Create a BytesIO object
        byte_io = io.BytesIO()
        # Save the image into the BytesIO object as PNG
        img.save(byte_io, format='PNG')
        # Reset the file pointer to the beginning
        byte_io.seek(0)
        return byte_io


# ì´ë¯¸ì§€ì„ ìºì‹œ ì €ì¥(ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ì‘ì—…ì„ ì²˜ë¦¬í•  ì˜ˆì •)
@st.cache_resource(show_spinner="ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤...")
def process_imagefile(ndarray_file):
    # ì—…ë¡œë“œí•œ íŒŒì¼ì„ ìºì‹œ ë””ë ‰í† ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤.
    file_content = png_to_bytesio(ndarray_file).getvalue()
    # file_content = file.read()
    current_time = datetime.now().strftime("%Y-%m-%d-%H-%M-%S")
    file_name = f"explain-drawing-{current_time}"
    # file_path = f"./.cache/files/{file.name}"
    file_path = f"./.cache/files/{file_name}"

    with open(file_path, "wb") as f:
        f.write(file_content)

    return file_path


# ì²´ì¸ ìƒì„±
def init_multimodal_chain(system_prompt, user_prompt=None, model_name="gpt-4o"):
    # ê°ì²´ ìƒì„±
    llm = ChatOpenAI(
        temperature=0,
        model_name=model_name,
        openai_api_key = st.session_state.api_key
    )
    # ë©€í‹°ëª¨ë‹¬ ê°ì²´ ìƒì„±
    multimodal = MultiModalwithHistory(llm, system_prompt=system_prompt, user_prompt=user_prompt)
    st.session_state["multimodal_chain"] = multimodal


# ì²´ì¸ ìƒì„±
# def create_chain(prompt_filepath, task=""):
#     # prompt ì ìš©
#     prompt = load_prompt(prompt_filepath, encoding="utf-8")

#     # ì¶”ê°€ íŒŒë¼ë¯¸í„°ê°€ ìˆìœ¼ë©´ ì¶”ê°€
#     if task:
#         prompt = prompt.partial(task=task)

#     # GPT
#     #llm = ChatOpenAI(model_name="gpt-4o", temperature=0)
#     llm = ChatOpenAI(model_name="gpt-4o", temperature=0, api_key=st.session_state.api_key)

#     # ì¶œë ¥ íŒŒì„œ
#     output_parser = StrOutputParser()

#     # ì²´ì¸ ìƒì„±
#     chain = prompt | llm | output_parser
#     return chain

if "explanation_user_drawing" in st.session_state and "explanation_user_reason" in st.session_state:
    
    init_multimodal_chain(
        system_prompt=system_prompt,
        model_name="gpt-4o"
    )
    
    # ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
    print_messages()

    # ì‚¬ìš©ìì˜ ì…ë ¥
    user_input = st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”!")
    image_filepath = process_imagefile(st.session_state["explanation_user_drawing"])

    # ë©€í‹°ëª¨ë‹¬ ê°ì²´ ìƒì„±
    multimodal = st.session_state["multimodal_chain"]

    if len(st.session_state["messages_explanation"]) == 0:
        init_user_input = f"ì´ ê·¸ë¦¼ì€ 'ì–´ë–¤ ë¬¼ì²´ê°€ ë“±ì† ì›ìš´ë™ì„ í•˜ê¸° ìœ„í•´ì„œ ë¬¼ì²´ì— ì–´ë–¤ ë°©í–¥ìœ¼ë¡œ í˜ì´ ì‘ìš©í•´ì•¼í•˜ëŠ”ê°€'ë¬¸ì œì— ëŒ€í•´ì„œ ë‚´ê°€ ìƒê°í•œ í˜ì˜ ë°©í–¥ì„ ê·¸ë¦° ê·¸ë¦¼ì´ì•¼. ê·¸ë¦¬ê³  ì´ë ‡ê²Œ ê·¸ë¦° ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ì•„: {st.session_state["explanation_user_reason"]}."
        # ë‹µë³€ ìš”ì²­
        response = multimodal.stream(
            user_prompt=init_user_input,
            image_url=image_filepath,
        )
        
        with st.chat_message("assistant"):
            # ë¹ˆ ê³µê°„(ì»¨í…Œì´ë„ˆ)ì„ ë§Œë“¤ì–´ì„œ, ì—¬ê¸°ì— í† í°ì„ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥í•œë‹¤.
            container = st.empty()

            ai_answer = ""
            for token in response:
                ai_answer += token.content
                container.markdown(ai_answer)

        # ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•œë‹¤.
        add_message("assistant", ai_answer)

    else:   
        if user_input:
            # ë‹µë³€ ìš”ì²­
            response = multimodal.stream(user_prompt=user_input)

            # ì‚¬ìš©ìì˜ ì…ë ¥
            st.chat_message("user").write(user_input)

            with st.chat_message("assistant"):
                # ë¹ˆ ê³µê°„(ì»¨í…Œì´ë„ˆ)ì„ ë§Œë“¤ì–´ì„œ, ì—¬ê¸°ì— í† í°ì„ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥í•œë‹¤.
                container = st.empty()

                ai_answer = ""
                for token in response:
                    ai_answer += token.content
                    container.markdown(ai_answer)
                
            multimodal.add_messages(
                role="ai",
                content=ai_answer
            )

            # ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•œë‹¤.
            add_message("user", user_input)
            add_message("assistant", ai_answer)


# Create columns with specific ratios
col1, col2, col3 = st.columns([5, 2, 3])

# Place the button in the last column
with col1:
    if st.button(
        label="ì´ì „ë‹¨ê³„ë¡œ ë„˜ì–´ê°€ê¸°",
        key="prev_button",
        icon="âª",
        help="ì‹œë®¬ë ˆì´ì…˜(O)ìœ¼ë¡œ ë„˜ì–´ê°€ê¸°",
        type="primary"
    ):
        st.switch_page("pages/03_ì‹œë®¬ë ˆì´ì…˜(O).py")

# Place the button in the last column
with col3:
    if st.button(
        label="ë‹¤ìŒë‹¨ê³„ë¡œ ë„˜ì–´ê°€ê¸°",
        key="next_button",
        icon="â©",
        help="ì ìš©í•˜ê¸°(A)ë¡œ ë„˜ì–´ê°€ê¸°",
        type="primary"
    ):
        st.switch_page("pages/05_ì ìš©í•˜ê¸°(A).py")
